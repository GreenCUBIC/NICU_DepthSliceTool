{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DATA_DIR = 'bagmerge/InterventionDetectionFiles/FirstFrameDepthRGB_origData/'\n",
    "TRAIN_DIR = ROOT_DATA_DIR + 'train/'\n",
    "TEST_DIR = ROOT_DATA_DIR + 'test/'\n",
    "VAL_DIR = ROOT_DATA_DIR + 'val/'\n",
    "TEST_SIZE = 0\n",
    "K_FOLDS = 5\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_HEIGHT = 224\n",
    "IMAGE_WIDTH = 224\n",
    "CLASS_WEIGHT = None\n",
    "INITIAL_BIAS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import libdst\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import shutil\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, Rescaling, Concatenate, Conv2D, Softmax, ReLU, Input\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.utils import image_dataset_from_directory, load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if len(physical_devices) > 0:\n",
    "#     tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "#     print(\"GPU memory growth enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noone_p1 = glob(ROOT_DATA_DIR + 'p1/noone/*.jpg')\n",
    "nurse_p1 = glob(ROOT_DATA_DIR + 'p1/nurse/*.jpg')\n",
    "noone_p2 = glob(ROOT_DATA_DIR + 'p2/noone/*.jpg')\n",
    "nurse_p2 = glob(ROOT_DATA_DIR + 'p2/nurse/*.jpg')\n",
    "noone_p5 = glob(ROOT_DATA_DIR + 'p5/noone/*.jpg')\n",
    "nurse_p5 = glob(ROOT_DATA_DIR + 'p5/nurse/*.jpg')\n",
    "noone_p6 = glob(ROOT_DATA_DIR + 'p6/noone/*.jpg')\n",
    "nurse_p6 = glob(ROOT_DATA_DIR + 'p6/nurse/*.jpg')\n",
    "noone_p8 = glob(ROOT_DATA_DIR + 'p8/noone/*.jpg')\n",
    "nurse_p8 = glob(ROOT_DATA_DIR + 'p8/nurse/*.jpg')\n",
    "noone_p9 = glob(ROOT_DATA_DIR + 'p9/noone/*.jpg')\n",
    "nurse_p9 = glob(ROOT_DATA_DIR + 'p9/nurse/*.jpg')\n",
    "noone_p10 = glob(ROOT_DATA_DIR + 'p10/noone/*.jpg')\n",
    "nurse_p10 = glob(ROOT_DATA_DIR + 'p10/nurse/*.jpg')\n",
    "noone_p11 = glob(ROOT_DATA_DIR + 'p11/noone/*.jpg')\n",
    "nurse_p11 = glob(ROOT_DATA_DIR + 'p11/nurse/*.jpg')\n",
    "noone_p13 = glob(ROOT_DATA_DIR + 'p13/noone/*.jpg')\n",
    "nurse_p13 = glob(ROOT_DATA_DIR + 'p13/nurse/*.jpg')\n",
    "noone_p14 = glob(ROOT_DATA_DIR + 'p14/noone/*.jpg')\n",
    "nurse_p14 = glob(ROOT_DATA_DIR + 'p14/nurse/*.jpg')\n",
    "noone_p15 = glob(ROOT_DATA_DIR + 'p15/noone/*.jpg')\n",
    "nurse_p15 = glob(ROOT_DATA_DIR + 'p15/nurse/*.jpg')\n",
    "noone_p16 = glob(ROOT_DATA_DIR + 'p16/noone/*.jpg')\n",
    "nurse_p16 = glob(ROOT_DATA_DIR + 'p16/nurse/*.jpg')\n",
    "noone_p17 = glob(ROOT_DATA_DIR + 'p17/noone/*.jpg')\n",
    "nurse_p17 = glob(ROOT_DATA_DIR + 'p17/nurse/*.jpg')\n",
    "# noone_p18 = glob(ROOT_DATA_DIR + 'p18/noone/*.jpg')\n",
    "# nurse_p18 = glob(ROOT_DATA_DIR + 'p18/nurse/*.jpg')\n",
    "# noone_p19 = glob(ROOT_DATA_DIR + 'p19/noone/*.jpg')\n",
    "# nurse_p19 = glob(ROOT_DATA_DIR + 'p19/nurse/*.jpg')\n",
    "noone_p21 = glob(ROOT_DATA_DIR + 'p21/noone/*.jpg')\n",
    "nurse_p21 = glob(ROOT_DATA_DIR + 'p21/nurse/*.jpg')\n",
    "noone_p22 = glob(ROOT_DATA_DIR + 'p22/noone/*.jpg')\n",
    "nurse_p22 = glob(ROOT_DATA_DIR + 'p22/nurse/*.jpg')\n",
    "noone_p23 = glob(ROOT_DATA_DIR + 'p23/noone/*.jpg')\n",
    "nurse_p23 = glob(ROOT_DATA_DIR + 'p23/nurse/*.jpg')\n",
    "noone_p24 = glob(ROOT_DATA_DIR + 'p24/noone/*.jpg')\n",
    "nurse_p24 = glob(ROOT_DATA_DIR + 'p24/nurse/*.jpg')\n",
    "noone_p25 = glob(ROOT_DATA_DIR + 'p25/noone/*.jpg')\n",
    "nurse_p25 = glob(ROOT_DATA_DIR + 'p25/nurse/*.jpg')\n",
    "noone_p26 = glob(ROOT_DATA_DIR + 'p26/noone/*.jpg')\n",
    "nurse_p26 = glob(ROOT_DATA_DIR + 'p26/nurse/*.jpg')\n",
    "noone_p27 = glob(ROOT_DATA_DIR + 'p27/noone/*.jpg')\n",
    "nurse_p27 = glob(ROOT_DATA_DIR + 'p27/nurse/*.jpg')\n",
    "noone_p28 = glob(ROOT_DATA_DIR + 'p28/noone/*.jpg')\n",
    "nurse_p28 = glob(ROOT_DATA_DIR + 'p28/nurse/*.jpg')\n",
    "noone_p29 = glob(ROOT_DATA_DIR + 'p29/noone/*.jpg')\n",
    "nurse_p29 = glob(ROOT_DATA_DIR + 'p29/nurse/*.jpg')\n",
    "noone_p30 = glob(ROOT_DATA_DIR + 'p30/noone/*.jpg')\n",
    "nurse_p30 = glob(ROOT_DATA_DIR + 'p30/nurse/*.jpg')\n",
    "noone_p31 = glob(ROOT_DATA_DIR + 'p31/noone/*.jpg')\n",
    "nurse_p31 = glob(ROOT_DATA_DIR + 'p31/nurse/*.jpg')\n",
    "noone_p32 = glob(ROOT_DATA_DIR + 'p32/noone/*.jpg')\n",
    "nurse_p32 = glob(ROOT_DATA_DIR + 'p32/nurse/*.jpg')\n",
    "noone_p33 = glob(ROOT_DATA_DIR + 'p33/noone/*.jpg')\n",
    "nurse_p33 = glob(ROOT_DATA_DIR + 'p33/nurse/*.jpg')\n",
    "noone_p34 = glob(ROOT_DATA_DIR + 'p34/noone/*.jpg')\n",
    "nurse_p34 = glob(ROOT_DATA_DIR + 'p34/nurse/*.jpg')\n",
    "# noone_p35 = glob(ROOT_DATA_DIR + 'p35/noone/*.jpg')\n",
    "# nurse_p35 = glob(ROOT_DATA_DIR + 'p35/nurse/*.jpg')\n",
    "# noone_p36 = glob(ROOT_DATA_DIR + 'p36/noone/*.jpg')\n",
    "# nurse_p36 = glob(ROOT_DATA_DIR + 'p36/nurse/*.jpg')\n",
    "# noone_p37 = glob(ROOT_DATA_DIR + 'p37/noone/*.jpg')\n",
    "# nurse_p37 = glob(ROOT_DATA_DIR + 'p37/nurse/*.jpg')\n",
    "# noone_p38 = glob(ROOT_DATA_DIR + 'p38/noone/*.jpg')\n",
    "# nurse_p38 = glob(ROOT_DATA_DIR + 'p38/nurse/*.jpg')\n",
    "\n",
    "# all_noone = noone_p1 + noone_p2 + noone_p5 + noone_p6 + noone_p8 + noone_p9 + noone_p10 + noone_p11 + noone_p13 + noone_p14 + noone_p15 + noone_p16 + noone_p17 + noone_p18 + noone_p19 + noone_p21 + noone_p22 + noone_p23 + noone_p24 + noone_p25 + noone_p26 + noone_p27 + noone_p28 + noone_p29 + noone_p30 + noone_p31 + noone_p32 + noone_p33 + noone_p34 + noone_p35 + noone_p36 + noone_p37 + noone_p38\n",
    "# all_nurse = nurse_p1 + nurse_p2 + nurse_p5 + nurse_p6 + nurse_p8 + nurse_p9 + nurse_p10 + nurse_p11 + nurse_p13 + nurse_p14 + nurse_p15 + nurse_p16 + nurse_p17 + nurse_p18 + nurse_p19 + nurse_p21 + nurse_p22 + nurse_p23 + nurse_p24 + nurse_p25 + nurse_p26 + nurse_p27 + nurse_p28 + nurse_p29 + nurse_p30 + nurse_p31 + nurse_p32 + nurse_p33 + nurse_p34 + nurse_p35 + nurse_p36 + nurse_p37 + nurse_p38\n",
    "\n",
    "# all_noone_list = [noone_p1, noone_p2, noone_p6, noone_p8, noone_p9, noone_p10, noone_p11, noone_p13, noone_p14, noone_p15, noone_p16, noone_p18, noone_p19, noone_p21, noone_p22, noone_p24, noone_p26, noone_p27, noone_p28, noone_p29, noone_p30, noone_p31, noone_p32, noone_p33, noone_p34, noone_p35, noone_p36, noone_p37, noone_p38]\n",
    "# all_nurse_list = [nurse_p1, nurse_p2, nurse_p6, nurse_p8, nurse_p9, nurse_p10, nurse_p11, nurse_p13, nurse_p14, nurse_p15, nurse_p16, nurse_p18, nurse_p19, nurse_p21, nurse_p22, nurse_p24, nurse_p26, nurse_p27, nurse_p28, nurse_p29, nurse_p30, nurse_p31, nurse_p32, nurse_p33, nurse_p34, nurse_p35, nurse_p36, nurse_p37, nurse_p38]\n",
    "\n",
    "# all_noone_list = [noone_p1, noone_p2, noone_p5, noone_p6, noone_p8, noone_p9, noone_p10, noone_p11, noone_p13, noone_p14, noone_p15, noone_p16, noone_p17, noone_p18, noone_p19, noone_p21, noone_p22, noone_p23, noone_p24, noone_p25, noone_p26, noone_p27, noone_p28, noone_p29, noone_p30, noone_p31, noone_p32, noone_p33, noone_p34, noone_p35, noone_p36, noone_p37, noone_p38]\n",
    "# all_nurse_list = [nurse_p1, nurse_p2, nurse_p5, nurse_p6, nurse_p8, nurse_p9, nurse_p10, nurse_p11, nurse_p13, nurse_p14, nurse_p15, nurse_p16, nurse_p17, nurse_p18, nurse_p19, nurse_p21, nurse_p22, nurse_p23, nurse_p24, nurse_p25, nurse_p26, nurse_p27, nurse_p28, nurse_p29, nurse_p30, nurse_p31, nurse_p32, nurse_p33, nurse_p34, nurse_p35, nurse_p36, nurse_p37, nurse_p38]\n",
    "\n",
    "all_noone_list = [noone_p1, noone_p2, noone_p5, noone_p6, noone_p8, noone_p9, noone_p10, noone_p11, noone_p13, noone_p14, noone_p15, noone_p16, noone_p17, noone_p21, noone_p22, noone_p23, noone_p24, noone_p25, noone_p26, noone_p27, noone_p28, noone_p29, noone_p30, noone_p31, noone_p32, noone_p33, noone_p34]\n",
    "all_nurse_list = [nurse_p1, nurse_p2, nurse_p5, nurse_p6, nurse_p8, nurse_p9, nurse_p10, nurse_p11, nurse_p13, nurse_p14, nurse_p15, nurse_p16, nurse_p17, nurse_p21, nurse_p22, nurse_p23, nurse_p24, nurse_p25, nurse_p26, nurse_p27, nurse_p28, nurse_p29, nurse_p30, nurse_p31, nurse_p32, nurse_p33, nurse_p34]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_noone_train = []\n",
    "# all_noone_test = []\n",
    "# for p in all_noone_list:\n",
    "#     if len(p) > 0:\n",
    "#         train, test = train_test_split(p, test_size=TEST_SIZE)\n",
    "#         all_noone_train += [train]\n",
    "#         all_noone_test += test\n",
    "\n",
    "# all_nurse_train = []\n",
    "# all_nurse_test = []\n",
    "# for p in all_nurse_list:\n",
    "#     if len(p) > 0:\n",
    "#         train, test = train_test_split(p, test_size=TEST_SIZE)\n",
    "#         all_nurse_train += [train]\n",
    "#         all_nurse_test += test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_noone_train = []\n",
    "all_noone_test = []\n",
    "all_nurse_train = []\n",
    "all_nurse_test = []\n",
    "\n",
    "if TEST_SIZE > 0:\n",
    "    train, test = train_test_split(range(len(all_noone_list)), test_size=TEST_SIZE)\n",
    "    \n",
    "    for i in train:\n",
    "        all_noone_train += [all_noone_list[i]]\n",
    "        all_nurse_train += [all_nurse_list[i]]\n",
    "\n",
    "    for i in test:\n",
    "        all_noone_test += all_noone_list[i]\n",
    "        all_nurse_test += all_nurse_list[i]\n",
    "elif TEST_SIZE == 0:\n",
    "    all_noone_train = all_noone_list\n",
    "    all_nurse_train = all_nurse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remFiles = glob(TEST_DIR + 'noone/'+ '*.jpg')\n",
    "for f in remFiles:\n",
    "    os.remove(f)\n",
    "\n",
    "remFiles = glob(TEST_DIR + 'nurse/'+ '*.jpg')\n",
    "for f in remFiles:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in all_noone_test:\n",
    "    basename = os.path.basename(f)\n",
    "    dst_path = TEST_DIR + 'noone/' + basename\n",
    "    shutil.copy(f, dst_path)\n",
    "\n",
    "for f in all_nurse_test:\n",
    "    basename = os.path.basename(f)\n",
    "    dst_path = TEST_DIR + 'nurse/' + basename\n",
    "    shutil.copy(f, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noone_test = glob(TEST_DIR + 'noone/*.jpg')\n",
    "nurse_test = glob(TEST_DIR + 'nurse/*.jpg')\n",
    "all_test = (noone_test, nurse_test)\n",
    "labels = ['noone', 'nurse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    rotation_range=360,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    ")\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    rotation_range=360,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    ")\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    rotation_range=360,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=123,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_batch, y_batch = next(test_generator)\n",
    "\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# plt.style.use('dark_background')\n",
    "# for k, (img, lbl) in enumerate(zip(x_batch, y_batch)):\n",
    "#     plt.subplot(4, 8, k+1)\n",
    "#     plt.imshow((img + 1) / 2)\n",
    "#     plt.title(\"Class: {}\".format(labels[int(lbl)]))\n",
    "#     plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model = VGG16(weights='imagenet', include_top=True)\n",
    "# test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model.layers[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trans_layers = test_model.layers[2:-1]\n",
    "# trans_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model.layers\n",
    "# w = test_model.layers[1].get_weights()[0][:, :, 2, :]\n",
    "# w = w.reshape(3, 3, 1, 64)\n",
    "# b = test_model.layers[1].get_weights()[1]\n",
    "# first_conv2d = Conv2D(64, kernel_size=3, padding='same', kernel_initializer=tf.keras.initializers.zeros(), use_bias=True, activation='relu')\n",
    "\n",
    "# model = tf.keras.Sequential(\n",
    "#     [\n",
    "#         tf.keras.Input(shape=(224, 224, 1),name='input'),\n",
    "#         first_conv2d,\n",
    "#         tf.keras.layers.Flatten(),\n",
    "#         tf.keras.layers.Dense(10, activation=\"relu\",use_bias=True,bias_initializer='zeros',name='dense1'),\n",
    "#         tf.keras.layers.Dense(1, activation=\"softmax\",name='output'),\n",
    "#     ]\n",
    "# )\n",
    "# model.layers[0].get_weights()[0].shape\n",
    "\n",
    "# model.layers[0].set_weights([w, b])\n",
    "# model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model.layers[2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "        # tf.keras.metrics.TruePositives(name='tp'),\n",
    "        # tf.keras.metrics.FalsePositives(name='fp'),\n",
    "        # tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "        # tf.keras.metrics.FalseNegatives(name='fn'),\n",
    "        # tf.keras.metrics.BinaryAccuracy(name='binary_accuracy'),\n",
    "        tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.AUC(name='AUC'),\n",
    "        tf.keras.metrics.AUC(name='prc', curve='PR'),\n",
    "    ]\n",
    "\n",
    "def create_model(finetuning=True, metrics=METRICS, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "\n",
    "    \n",
    "    base_model = VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "    first_conv2d_bias = base_model.layers[1].get_weights()[-1]\n",
    "    first_conv2d_weights = base_model.layers[1].get_weights()[0][:, :, 2, :].reshape(3, 3, 1, 64)\n",
    "    \n",
    "    custom_input = Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 1), name=\"1-Channel_input\")\n",
    "    first_conv2d = Conv2D(64, kernel_size=3, padding='same', name=\"First_Conv2D\")\n",
    "    transfer_layers = base_model.layers[2:-1]\n",
    "    predictions = Dense(2, activation=\"softmax\", name=\"prediction_layer\", bias_initializer=output_bias)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(custom_input)\n",
    "    model.add(first_conv2d)\n",
    "    model.add(ReLU())\n",
    "\n",
    "    model.layers[0].set_weights([first_conv2d_weights, first_conv2d_bias])\n",
    "\n",
    "    for layer in transfer_layers:\n",
    "        # print(layer)\n",
    "        model.add(layer)\n",
    "\n",
    "    model.add(predictions)\n",
    "\n",
    "    model.compile(\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "        # Use this for \n",
    "        optimizer=tf.optimizers.SGD(0.00001, momentum=0.9),\n",
    "        # optimizer=tf.optimizers.SGD(),\n",
    "        metrics=[METRICS],\n",
    "        )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepFiles(noone_train, nurse_train, noone_val, nurse_val):\n",
    "    # Clean up train and val folders\n",
    "    remFiles = glob(TRAIN_DIR + 'noone/'+ '*.jpg')\n",
    "    for f in remFiles:\n",
    "        os.remove(f)\n",
    "    remFiles = glob(TRAIN_DIR + 'nurse/'+ '*.jpg')\n",
    "    for f in remFiles:\n",
    "        os.remove(f)\n",
    "    remFiles = glob(VAL_DIR + 'noone/'+ '*.jpg')\n",
    "    for f in remFiles:\n",
    "        os.remove(f)\n",
    "    remFiles = glob(VAL_DIR + 'nurse/'+ '*.jpg')\n",
    "    for f in remFiles:\n",
    "        os.remove(f)\n",
    "\n",
    "    # Move files of current fold into their folders\n",
    "    for f in noone_train:\n",
    "        basename = os.path.basename(f)\n",
    "        dst_path = TRAIN_DIR + 'noone/' + basename\n",
    "        shutil.copy(f, dst_path)\n",
    "    for f in nurse_train:\n",
    "        basename = os.path.basename(f)\n",
    "        dst_path = TRAIN_DIR + 'nurse/' + basename\n",
    "        shutil.copy(f, dst_path)\n",
    "    for f in noone_val:\n",
    "        basename = os.path.basename(f)\n",
    "        dst_path = VAL_DIR + 'noone/' + basename\n",
    "        shutil.copy(f, dst_path)\n",
    "    for f in nurse_val:\n",
    "        basename = os.path.basename(f)\n",
    "        dst_path = VAL_DIR + 'nurse/' + basename\n",
    "        shutil.copy(f, dst_path)\n",
    "\n",
    "    noone_train = glob(TRAIN_DIR + 'noone/*.jpg')\n",
    "    nurse_train = glob(TRAIN_DIR + 'nurse/*.jpg')\n",
    "\n",
    "    noone_val = glob(VAL_DIR + 'noone/*.jpg')\n",
    "    nurse_val = glob(VAL_DIR + 'nurse/*.jpg')\n",
    "\n",
    "    return noone_train, nurse_train, noone_val, nurse_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=K_FOLDS)\n",
    "cv_split = kf.split(range(len(all_noone_train)))\n",
    "foldNum = 0\n",
    "\n",
    "foldHistories = []\n",
    "# foldMetrics = []\n",
    "\n",
    "# with tf.device('/CPU:0'):\n",
    "for train_index, val_index in cv_split:\n",
    "    print(\"Fold {}: \\n\".format(foldNum))\n",
    "\n",
    "    # Select the current folds for training and validation\n",
    "    noone_train = []\n",
    "    nurse_train = []\n",
    "    noone_val = []\n",
    "    nurse_val = []\n",
    "    for i in train_index:\n",
    "        noone_train += all_noone_train[i]\n",
    "        nurse_train += all_nurse_train[i]\n",
    "    for i in val_index:\n",
    "        noone_val += all_noone_train[i]\n",
    "        nurse_val += all_nurse_train[i]\n",
    "\n",
    "    # Move images to training and testing folders\n",
    "    noone_train, nurse_train, noone_val, nurse_val = prepFiles(noone_train, nurse_train, noone_val, nurse_val)\n",
    "    all_train = [noone_train, nurse_train]\n",
    "    all_val = [noone_val, nurse_val]\n",
    "\n",
    "    print(\"noone_train: {}, nurse_train: {}\".format(len(noone_train), len(nurse_train)))\n",
    "    print(\"noone_val: {}, nurse_val: {}\\n\".format(len(noone_val), len(nurse_val)))\n",
    "\n",
    "    weight_for_0 = (1 / (len(noone_train) + len(noone_val))) * ((len(nurse_train) + len(nurse_val) + len(noone_train) + len(noone_val)) / 2.0)\n",
    "    weight_for_1 = (1 / (len(nurse_train) + len(nurse_val))) * ((len(nurse_train) + len(nurse_val) + len(noone_train) + len(noone_val)) / 2.0)\n",
    "    CLASS_WEIGHT = {0: weight_for_0, 1: weight_for_1}\n",
    "    print(\"Class Weights: {}\\n\".format(CLASS_WEIGHT))\n",
    "    \n",
    "    INITIAL_BIAS = np.log([(len(nurse_train) + len(nurse_val)) / (len(noone_train) + len(noone_val))])\n",
    "    print(\"Initial Bias: {}\\n\".format(INITIAL_BIAS))\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        TRAIN_DIR,\n",
    "        target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "        color_mode='grayscale',\n",
    "        class_mode='categorical',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        seed=123,\n",
    "    )\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        VAL_DIR,\n",
    "        target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "        color_mode='grayscale',\n",
    "        class_mode='categorical',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        seed=123,\n",
    "    )\n",
    "\n",
    "    # model = create_model(output_bias=INITIAL_BIAS)\n",
    "    model = create_model()\n",
    "    model.summary()\n",
    "    checkpoint_path = \"SavedModels/cp_fold_{}_lab.ckpt\".format(foldNum)\n",
    "    checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_prc', verbose=1, save_best_only=True, save_weights_only=True, mode='auto')\n",
    "    earlyStopping = EarlyStopping(monitor='prc', min_delta=0, patience=8, verbose=1, mode='auto')\n",
    "\n",
    "    history = model.fit(\n",
    "        x=train_generator,\n",
    "        epochs=20,\n",
    "        # validation_data=val_generator,\n",
    "        # validation_steps=1,\n",
    "        # callbacks=[checkpoint],\n",
    "        # callbacks=[checkpoint, earlyStopping],\n",
    "        # class_weight=CLASS_WEIGHT,\n",
    "    )\n",
    "\n",
    "    model.save_weights(checkpoint_path)\n",
    "\n",
    "    foldHistories.append(history)\n",
    "\n",
    "    # metrics = model.evaluate(test_generator, return_dict=True)\n",
    "    # for name, value in metrics.items():\n",
    "    #     print(f\"{name}: {value:.4f}\")\n",
    "\n",
    "    # foldMetrics.append(metrics)\n",
    "\n",
    "    foldNum += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "noone_test_final = glob(TEST_DIR + 'noone/*.jpg')\n",
    "nurse_test_final = glob(TEST_DIR + 'nurse/*.jpg')\n",
    "print(\"Test set includes {} negatives and {} positives\".format(len(noone_test_final), len(nurse_test_final)))\n",
    "\n",
    "def printCM(cm, labels):\n",
    "    ax = plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax=ax)\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.xaxis.set_ticklabels(labels)\n",
    "    ax.yaxis.set_ticklabels(labels)\n",
    "    return\n",
    "\n",
    "def predictNurse(model, img):\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    preds = model.predict(x, verbose=0)\n",
    "    label = 'nurse' if preds[0][1]>preds[0][0] else 'noone'\n",
    "    return label\n",
    "\n",
    "def evalModel(model):\n",
    "    preds = []\n",
    "    truths = []\n",
    "    for i in range(len(noone_test_final)):\n",
    "        im = load_img(noone_test_final[i], color_mode='grayscale', target_size=(IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        label = predictNurse(model, im)\n",
    "        preds.append(label)\n",
    "        truths.append('noone')\n",
    "\n",
    "    for i in range(len(nurse_test_final)):\n",
    "        im = load_img(nurse_test_final[i], color_mode='grayscale', target_size=(IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        label = predictNurse(model, im)\n",
    "        preds.append(label)\n",
    "        truths.append('nurse')\n",
    "\n",
    "    labels = ['noone', 'nurse']\n",
    "    cm = confusion_matrix(truths, preds)\n",
    "    printCM(cm, labels)\n",
    "\n",
    "    TN = cm[0][0]\n",
    "    FP = cm[0][1]\n",
    "    FN = cm[1][0]\n",
    "    TP = cm[1][1]\n",
    "    prec = TP / (TP + FP)\n",
    "    spec = TN / (TN + FP)\n",
    "    sens = TP / (TP + FN)\n",
    "    acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "    f1 = (2 * TP) / ((2 * TP) + FP + FN)\n",
    "    print(\"Sens: {}, Spec: {}, Prec: {}, Acc: {}, F1: {}\".format(sens, spec, prec, acc, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_split_testing = kf.split(range(len(all_noone_train)))\n",
    "# for train_index, val_index in cv_split_testing:\n",
    "#     for i in val_index:\n",
    "#         print(all_nurse_list[i][0])\n",
    "#     print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_split_testing = kf.split(range(len(all_noone_train)))\n",
    "foldNum_testing = 0\n",
    "\n",
    "# with tf.device('/CPU:0'):\n",
    "for train_index, val_index in cv_split_testing:\n",
    "    print(\"Fold {}:\".format(foldNum_testing))\n",
    "\n",
    "    # Select the current folds for training and validation\n",
    "    noone_train = []\n",
    "    nurse_train = []\n",
    "    noone_val = []\n",
    "    nurse_val = []\n",
    "    for i in train_index:\n",
    "        noone_train += all_noone_train[i]\n",
    "        nurse_train += all_nurse_train[i]\n",
    "    for i in val_index:\n",
    "        noone_val += all_noone_train[i]\n",
    "        nurse_val += all_nurse_train[i]\n",
    "\n",
    "    # Move images to training and testing folders\n",
    "    noone_train, nurse_train, noone_val, nurse_val = prepFiles(noone_train, nurse_train, noone_val, nurse_val)\n",
    "    all_train = [noone_train, nurse_train]\n",
    "    all_val = [noone_val, nurse_val]\n",
    "\n",
    "    noone_test_final = glob(VAL_DIR + 'noone/*.jpg')\n",
    "    nurse_test_final = glob(VAL_DIR + 'nurse/*.jpg')\n",
    "\n",
    "\n",
    "    print(\"noone_train: {}, nurse_train: {}\".format(len(noone_train), len(nurse_train)))\n",
    "    print(\"noone_val: {}, nurse_val: {}\\n\".format(len(noone_val), len(nurse_val)))\n",
    "\n",
    "    model = create_model()\n",
    "    model.load_weights(\"SavedModels/cp_fold_{}_lab.ckpt\".format(foldNum_testing))\n",
    "    \n",
    "    evalModel(model)\n",
    "    \n",
    "\n",
    "    foldNum_testing += 1\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dcc3702ba4673e5f54fdd3709fe5ed25d29336674f2bae745d90e34c29bbdc23"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('RS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
